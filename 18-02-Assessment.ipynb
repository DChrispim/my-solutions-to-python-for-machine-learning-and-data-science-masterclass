{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "___\n",
    "\n",
    "<a href='http://www.pieriandata.com'> <img src='../Pierian_Data_Logo.png' /></a>\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification Assessment \n",
    "\n",
    "### Goal: Given a set of text movie reviews that have been labeled negative or positive\n",
    "\n",
    "For more information on this dataset visit http://ai.stanford.edu/~amaas/data/sentiment/\n",
    "\n",
    "## Complete the tasks in bold below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task: Perform imports and load the dataset into a pandas DataFrame**\n",
    "For this exercise you can load the dataset from `'../DATA/moviereviews.csv'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../DATA/moviereviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>how do films like mouse hunt get into theatres...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>some talented actresses are blessed with a dem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pos</td>\n",
       "      <td>this has been an extraordinary year for austra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pos</td>\n",
       "      <td>according to hollywood movies made in last few...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>my first press screening of 1998 and already i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                             review\n",
       "0   neg  how do films like mouse hunt get into theatres...\n",
       "1   neg  some talented actresses are blessed with a dem...\n",
       "2   pos  this has been an extraordinary year for austra...\n",
       "3   pos  according to hollywood movies made in last few...\n",
       "4   neg  my first press screening of 1998 and already i..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Check to see if there are any missing values in the dataframe.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label      0\n",
       "review    35\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Remove any reviews that are NaN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     0\n",
       "review    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Check to see if any reviews are blank strings and not just NaN. Note: This means a review text could just be: \"\" or \"  \" or some other larger blank string. How would you check for this? Note: There are many ways! Once you've discovered the reviews that are blank strings, go ahead and remove them as well. [Click me for a big hint](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.str.isspace.html)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively it is possible to use the function\n",
    "\n",
    "    df[\"review\"].str.isspace()\n",
    "\n",
    "that returns a booleand list indicating if the string consists of only spaces (any number). To get the opositve of the booleand just add \"~\" to the code as the example\n",
    "\n",
    "    df[~df[\"review\"].str.isspace()]\n",
    "\n",
    "that will return all the entrys that are not only spaces. Notice that the case with \"\" needs to treated using the condition\n",
    "\n",
    "    df[df['review'].apply(lambda review: review == \"\"]\n",
    "    \n",
    "or using the method that I used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label     27\n",
       "review    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['review'].apply(lambda text: len(text)) < 3].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1299</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1455</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1493</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1851</th>\n",
       "      <td>neg</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>pos</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label review\n",
       "57     neg       \n",
       "71     pos       \n",
       "147    pos       \n",
       "151    pos       \n",
       "283    pos       \n",
       "307    pos       \n",
       "313    neg       \n",
       "323    pos       \n",
       "343    pos       \n",
       "351    neg       \n",
       "427    pos       \n",
       "501    neg       \n",
       "633    pos       \n",
       "675    neg       \n",
       "815    neg       \n",
       "851    neg       \n",
       "977    neg       \n",
       "1079   neg       \n",
       "1299   pos       \n",
       "1455   neg       \n",
       "1493   pos       \n",
       "1525   neg       \n",
       "1531   neg       \n",
       "1763   neg       \n",
       "1851   neg       \n",
       "1905   pos       \n",
       "1993   pos       "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['review'].apply(lambda text: len(text)) < 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(df[df['review'].apply(lambda text: len(text)) < 3].index,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1938 entries, 0 to 1999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   1938 non-null   object\n",
      " 1   review  1938 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 45.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Confirm the value counts per label:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>neg</th>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pos</th>\n",
       "      <td>969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review\n",
       "label        \n",
       "neg       969\n",
       "pos       969"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"label\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA on Bag of Words\n",
    "\n",
    "**Bonus Task: Can you figure out how to use a CountVectorizer model to get the top 20 words (that are not english stop words) per label type? Note, this is a bonus task as we did not show this in the lectures. But a quick cursory Google search should put you on the right path.  [Click me for a big hint](https://stackoverflow.com/questions/16288497/find-the-most-common-term-in-scikit-learn-classifier)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words used for Positive reviews.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('film', 5002),\n",
       " ('movie', 2389),\n",
       " ('like', 1721),\n",
       " ('just', 1273),\n",
       " ('story', 1199),\n",
       " ('good', 1193),\n",
       " ('time', 1175),\n",
       " ('character', 1037),\n",
       " ('life', 1032),\n",
       " ('characters', 957),\n",
       " ('way', 864),\n",
       " ('films', 851),\n",
       " ('does', 828),\n",
       " ('best', 788),\n",
       " ('people', 769),\n",
       " ('make', 764),\n",
       " ('little', 751),\n",
       " ('really', 731),\n",
       " ('man', 728),\n",
       " ('new', 702)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer\n",
    "\n",
    "# Top words for positive reviews\n",
    "\n",
    "# Create the bag of words, exclude english common words\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the reviews that are only positive and transform in pandas series\n",
    "data = df[df[\"label\"]==\"pos\"][\"review\"] # Only label with pos reviews\n",
    "sparse_mat_pos = cv.fit_transform(data) # Fit the pandas table\n",
    "extract = np.array(sparse_mat_pos.sum(axis = 0))[0] # Unpack the sparse matrix sum (which sums the columns, gives total word count)\n",
    "\n",
    "# The word_series relates the index of the word to the number of times it appears in the data\n",
    "n = -20 # number of words\n",
    "word_series = pd.Series(extract).sort_values()[n:] # Transform in pd series, easy to sort and keep the index (for word dic)\n",
    "\n",
    "# Create the word dic\n",
    "word_dict = cv.vocabulary_ # Dic linking the index in word_series to the word\n",
    "\n",
    "# Function to extract the key based on the value (https://www.geeksforgeeks.org/python-get-key-from-value-in-dictionary/)\n",
    "def get_key(val):\n",
    "    \n",
    "    for key, value in word_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "# Top word list\n",
    "top_words = []\n",
    "\n",
    "# Append each word and its count to a list in tuple format\n",
    "for index in word_series.index:\n",
    "    top_words.append((get_key(index),word_series[index]))\n",
    "\n",
    "# Reverse the order of the list to show in decresing order\n",
    "top_words.reverse()\n",
    "print(\"Top {} words used for Positive reviews.\".format(-n))\n",
    "top_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 words used for Negative reviews.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('film', 4063),\n",
       " ('movie', 3131),\n",
       " ('like', 1808),\n",
       " ('just', 1480),\n",
       " ('time', 1127),\n",
       " ('good', 1117),\n",
       " ('bad', 997),\n",
       " ('character', 926),\n",
       " ('story', 908),\n",
       " ('plot', 888),\n",
       " ('characters', 838),\n",
       " ('make', 813),\n",
       " ('really', 743),\n",
       " ('way', 734),\n",
       " ('little', 696),\n",
       " ('don', 683),\n",
       " ('does', 666),\n",
       " ('doesn', 648),\n",
       " ('action', 635),\n",
       " ('scene', 634)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer\n",
    "\n",
    "# Top words for positive reviews\n",
    "\n",
    "# Create the bag of words, exclude english common words\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "\n",
    "# Fit the reviews that are only positive and transform in pandas series\n",
    "data = df[df[\"label\"]==\"neg\"][\"review\"] # Only label with pos reviews\n",
    "sparse_mat_pos = cv.fit_transform(data) # Fit the pandas table\n",
    "extract = np.array(sparse_mat_pos.sum(axis = 0))[0] # Unpack the sparse matrix sum (which sums the columns, gives total word count)\n",
    "\n",
    "# The word_series relates the index of the word to the number of times it appears in the data\n",
    "n = -20 # number of words\n",
    "word_series = pd.Series(extract).sort_values()[n:] # Transform in pd series, easy to sort and keep the index (for word dic)\n",
    "\n",
    "# Create the word dic\n",
    "word_dict = cv.vocabulary_ # Dic linking the index in word_series to the word\n",
    "\n",
    "# Function to extract the key based on the value (https://www.geeksforgeeks.org/python-get-key-from-value-in-dictionary/)\n",
    "def get_key(val):\n",
    "    \n",
    "    for key, value in word_dict.items():\n",
    "        if val == value:\n",
    "            return key\n",
    " \n",
    "    return \"key doesn't exist\"\n",
    "\n",
    "# Top word list\n",
    "top_words = []\n",
    "\n",
    "# Append each word and its count to a list in tuple format\n",
    "for index in word_series.index:\n",
    "    top_words.append((get_key(index),word_series[index]))\n",
    "\n",
    "# Reverse the order of the list to show in decresing order\n",
    "top_words.reverse()\n",
    "print(\"Top {} words used for Negative reviews.\".format(-n))\n",
    "top_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Data\n",
    "\n",
    "**TASK: Split the data into features and a label (X and y) and then preform a train/test split. You may use whatever settings you like. To compare your results to the solution notebook, use `test_size=0.20, random_state=101`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['label']\n",
    "X = df['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training a Mode\n",
    "\n",
    "**TASK: Create a PipeLine that will both create a TF-IDF Vector out of the raw text data and fit a supervised learning model of your choice. Then fit that pipeline on the training data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('tfidf',TfidfVectorizer()),\n",
    "                 ('svc',LinearSVC())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('svc', LinearSVC())])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK: Create a classification report and plot a confusion matrix based on the results of your PipeLine.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix,classification_report, confusion_matrix, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.81      0.86      0.83       191\n",
      "         pos       0.85      0.81      0.83       197\n",
      "\n",
      "    accuracy                           0.83       388\n",
      "   macro avg       0.83      0.83      0.83       388\n",
      "weighted avg       0.83      0.83      0.83       388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = pipe.predict(X_test)\n",
    "print(classification_report(y_test,preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x28c4c9fb460>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
